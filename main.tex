\documentclass[chapterprefix=false, 12pt, a4paper, oneside, parskip=half, listof=totoc, bibliography=totoc, numbers=noendperiod]{scrbook}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[bottom=48mm,left=25mm,right=25mm]{geometry}
\usepackage[onehalfspacing]{setspace}
\usepackage[stretch=10]{microtype}
\usepackage{xcolor}
\usepackage{scrhack}
\usepackage{titling}
\usepackage{minted}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[ngerman]{babel}
\usepackage{biblatex}
\usepackage[outdir=./]{epstopdf}
\pdfminorversion=7
\usepackage{csquotes}


\renewcommand*{\chapterheadstartvskip}{\vspace*{.25\baselineskip}}
\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist

\definecolor{htwgruen}{RGB}{118, 185, 0}
\definecolor{htwblau}{RGB}{0, 130, 209}
\definecolor{htworange}{RGB}{255, 95, 0}
\definecolor{htwgrau}{RGB}{175, 175, 175}

\title{Problemlogbuch I}

\author{Nadzeya Ilyina 556687\\
Sebastian Jüngling 558556\\
Roman Laas 547499\\
Marc Schmeling 553407\\
Christoph Stach 555912}

\date{26.10.2018 bis 23.11.2018}

\addbibresource{main.bib}

\defbibheading{none}[\bibname]{
%%
}

\begin{document}
    \begin{titlepage}
        % Logo
        \includegraphics[width=0.50\textwidth]{img/Q01_HTW_Berlin_Logo_quer_pos_FARBIG_CMYK.eps}

        % Abstand nach logo
        \vspace{4.0cm}

        % Textkörper
        \begin{changemargin}{0.5cm}{0.0cm}
            % Dokumenttyp
            \color{htwgrau}
            \normalsize
            \textsf{\noindent\MakeUppercase{Dokumenttyp}} \vspace{-20pt}\\

            % Horizontale Linie
            \noindent\rule{\textwidth}{0.5pt}\vspace{-4pt}
            
            % Title
            \color{black}
            \huge
            \textsf{\thetitle}
            \vspace{12pt}

            % Authoren
            \color{htwgrau}
            \normalsize
            \textsf{\MakeUppercase{Autoren}}\\
            \color{black}
            \large
            \textsf{\theauthor}

            \vfill

            % Zeitraum
            \color{htwgrau}
            \normalsize
            \textsf{\MakeUppercase{Zeitraum}}\\
            \color{black}
            \large
            \textsf{\thedate}

            % Modul
            \color{htwgrau}
            \normalsize
            \textsf{\MakeUppercase{Modul}}\\
            \color{black}
            \large
            \textsf{Spezielle Anwendungen der Informatik: Do-IT-yourself: Semantische Suche}

            % Dozent
            \color{htwgrau}
            \normalsize
            \textsf{\MakeUppercase{Dozent}}\\
            \color{black}
            \large
            \textsf{Dr. rer. nat. Thomas Hoppe}


            % Am Ende der Seite

        \end{changemargin}
    \end{titlepage}

	% Inhaltsverzeichnis
    \tableofcontents

    \chapter{Aufgabenverteilung}
\begin{itemize}
	\item[$$] Moderation: Sebastian Jüngling
	\item[$$] Protokoll: Roman Laas
\end{itemize}

    \chapter{Abstract}

    \chapter{Formulierung der Lernziele}

\begin{itemize}
\item[$-$] Wir möchten die Einsatzberichte der Berliner Polizei mithilfe eines Webcrawlers automatisiert erheben. Dabei werden wir uns auf eine Implementierung in Python konzentrieren und gleichzeitig einen alternativen Webcrawler in der Programmiersprache Rust entwickeln. Die Ergebnisse werden in eine MongoDB gespeichert und anschließend verglichen.
\item[$-$] Wir möchten die erhobenen Einsatzberichte für die weitere Verwendung aufbereiten.
\end{itemize}

	\chapter{Einleitung}

\section{Webcrawler (Laas)}
Mit der Kommerzialisierung des World Wide Web Anfang bis Mitte der 90er Jahre und dem damit verbundenen Boom an neuen Informationen auf neuen Plattformen stieg bei den Nutzern der Bedarf an Orientierung und Ordnung. In dieser Zeit formten sich die ersten Suchmaschinen, von denen die meisten heute nicht mehr bekannt oder sogar nicht mehr existent sind. Obwohl es auch händisch gepflegte Katalog-Suchmaschinen wie das damalige Yahoo! gab, setzten schon in den ersten Jahren viele Anbieter auf Webcrawler.\\\\
Webcrawler sind Computerprogramme, die das Internet wiederholt automatisch durchsuchen und analysieren. Der Name (zu deutsch wörtlich Raupe) etablierte sich mit der Suchmaschine ''WebCrawler'', welche als eine der ersten eine Volltextindex-Suche anbot. Crawler ermöglichen Suchmaschinen die Pflege des Index indem sie neue, veränderte oder gelöschte Ressourcen finden. Die übliche Vorgehensweise beim ''crawlen'' ist dabei das Abarbeiten von Hyperlinks auf analysierten Webseiten. So können theoretisch alle verlinkten und öffentlich zugänglichen Seiten gefunden werden.

\section{Robots Exclusion Standart (Laas)}
Schon mit dem Aufkommen der ersten Webcrawler bemerkte man, dass diese häufig für Engpässe oder gar Ausfälle (Denial of Service) bei der Verfügbarkeit von Webservern verantwortlich waren. Im Frühjahr 1994 schlug Martijn Koster deshalb über den damals viel beachteten ''www-talk'' Mailverteiler die Nutzung einer robots.txt vor, welche solche Probleme in Zukunft verhindern oder zumindest abmildern soll. Webseitenbetreiber sollten diese Datei hierfür in einem einheitlichen Format im Stammverzeichnis ihrer Domain anlegen und mit Anweisungen und Regeln an Webcrawler füllen. Die Idee fand großen Anklang und wurde in kurzer Zeit zum de facto Standard erhoben.\\
tbf Erläuterung Format

	\chapter{Implementierung}
	\chapter{Speicherung}
	\chapter{Textaufbereitung}
	\section{Section}
	\subsection{Subsection}
	\subsubsection{Subsubsection}

    \section{Beispiel Syntax-HL}
    \begin{minted}[xleftmargin=20pt,linenos,breaklines]{javascript}
    function DividendsController(apiClient, \$q, \$state, \$scope) {
        var vm = this;
        vm.saved = false;

        function onStateChange(event, toState, toParams) {
            if (!vm.saved) {
                if (!confirm('Wollen Sie die Seite...?')) {
                    event.preventDefault();
                }
            }
        }
    }
    \end{minted}

    % \chapter{Anhang}

    % \section{Literaturverzeichnis}

    % \printbibliography[heading=none]

    % \section{Glossar}
\end{document}
